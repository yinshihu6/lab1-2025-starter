{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "In this lab, we will explore the tensor operations underlying deep neural\n",
    "networks. To get you started we have provided a \"deep\" network in this notebook.\n",
    "Run the ipython notebook as you go along and answer the questions. Most\n",
    "questions below have a *small* coding component (you only need to edit code when\n",
    "specifically asked to).\n",
    "\n",
    "# Assigned reading:\n",
    "Chapters 1-3 of textbook\n",
    "\n",
    "## Part 1: PyTorch DNNs\n",
    "We'll first implement a simple convolutional neural network to classify MNIST\n",
    "digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "\n",
    "# All of these blocks must be filled out in all notebooks in order for the lab\n",
    "# to be marked complete.\n",
    "\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your name?',\n",
    "    answer= 'FILL ME',\n",
    "    required_type=str,\n",
    ")\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your email address?',\n",
    "    answer= 'FILL ME',\n",
    "    required_type=str,\n",
    ")\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your kerberos?',\n",
    "    answer= 'FILL ME',\n",
    "    required_type=str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MNIST dataset\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = 10000\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(6825)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50, sampler=train_sampler, shuffle=False)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(trainset, batch_size=50, sampler=valid_sampler, shuffle=False)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 5, padding = 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 5, padding = 2)\n",
    "        self.fc1 = nn.Linear(8 * 7 * 7, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below trains for `NUM_EPOCHS` number of epochs and plots the training error. If you want (not graded), you can update this function to calculate the validation accuracy after each epoch so that you can plot it later. You can then play around with the number of epochs to see how it affects the validation accuracy (also not graded).\n",
    "\n",
    "Note: The initialization below is not strictly necessary, as PyTorch will automoatically initialize the weights (including biases) for you. We've included initialization here so that if you run the cell more than once, you will start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc_vect = np.zeros(NUM_EPOCHS)\n",
    "valid_acc_vect = np.zeros(NUM_EPOCHS)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize weights and biases\n",
    "nn.init.kaiming_uniform_(net.conv1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv1.bias.size(0))\n",
    "nn.init.uniform_(net.conv1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.conv2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.conv2.bias.size(0))\n",
    "nn.init.uniform_(net.conv2.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc1.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc1.bias.size(0))\n",
    "nn.init.uniform_(net.fc1.bias, -stdv, stdv)\n",
    "nn.init.kaiming_uniform_(net.fc2.weight, nonlinearity = 'relu')\n",
    "stdv = 1./np.sqrt(net.fc2.bias.size(0))\n",
    "nn.init.uniform_(net.fc2.bias, -stdv, stdv)\n",
    "\n",
    "# train network\n",
    "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times while training\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data # list of [inputs, labels]\n",
    "        #print(labels.shape)\n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = net(inputs) # forward step\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # optimize weights\n",
    "\n",
    "        # print statistics\n",
    "        duration = time.time() - start_time\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    training_acc = correct_train / total_train * 100\n",
    "    training_acc_vect[epoch] = training_acc\n",
    "    \n",
    "    print('Accuracy of the network on the 50000 training images after epoch %d: %.2f %% (%.1f sec)' % (\n",
    "        epoch + 1, training_acc, duration))\n",
    "    \n",
    "    # your code here to calculate the validation error after each epoch\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vect = np.linspace(1, NUM_EPOCHS, NUM_EPOCHS)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_vect, 100-training_acc_vect)\n",
    "\n",
    "print(\"Final Training Accuracy: %g\" % (training_acc))\n",
    "\n",
    "# Your code here to plot validation error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='1.1',\n",
    "    subquestion=\"\"\"\n",
    "    The training accuracy is always a good indicator of the model performance on\n",
    "    unseen data.\n",
    "    \"\"\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=('True', 'False'),\n",
    ")\n",
    "answer(\n",
    "    question='1.1',\n",
    "    subquestion=\"\"\"\n",
    "    Which accuracy is the better indicator of the model performance on unseen\n",
    "    data?\n",
    "    \"\"\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=('Training Accuracy', 'Test Accuracy'),\n",
    ")\n",
    "answer(\n",
    "    question='1.1',\n",
    "    subquestion=\"\"\"\n",
    "    You have trained and tested the model on images give with white digits on a\n",
    "    black background. However, you now want to use the model to classify images\n",
    "    with black digits on a white background. How would you expect the model's\n",
    "    accuracy to change?\n",
    "    \"\"\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=('Accuracy Increase', 'Accuracy Decrease', 'No Change'),\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='1.1',\n",
    "    subquestion=\"\"\"\n",
    "    The white-with-black-background images are from the _____ distribution\n",
    "    compared to your training and testing data.\n",
    "    \"\"\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=('Same', 'Different'),\n",
    ")\n",
    "\n",
    "PATH = './my_mnist_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference using the trained model and print the training, validation and test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_net = Net()\n",
    "\n",
    "def eval_model(PATH, trainloader, validloader, testloader):\n",
    "\n",
    "    # your code here\n",
    "    training_accuracy = 0\n",
    "    validation_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    return training_accuracy, validation_accuracy, test_accuracy\n",
    "\n",
    "training_accuracy, validation_accuracy, test_accuracy = eval_model(PATH, trainloader, validloader, testloader)\n",
    "print('Training Accuracy: %g' % training_accuracy)        \n",
    "print('Validation Accuracy: %g' % validation_accuracy)\n",
    "print('Test Accuracy: %g' % test_accuracy)\n",
    "\n",
    "answer(\n",
    "    question=\"1.2\",\n",
    "    subquestion=\"What is the training accuracy of the model?\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=Number,\n",
    ")\n",
    "answer(\n",
    "    question=\"1.2\",\n",
    "    subquestion=\"What is the validation accuracy of the model?\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=Number,\n",
    ")\n",
    "answer(\n",
    "    question=\"1.2\",\n",
    "    subquestion=\"What is the test accuracy of the model?\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=Number,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first test image and label. Similarly visualize the weights of the\n",
    "filters used in the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test set using torchvision\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "\n",
    "# convert to numpy array\n",
    "images_array = torch.zeros((10000,28,28))\n",
    "labels_array = torch.zeros(10000)\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    image, label = data\n",
    "    images_array[i,:,:] = image\n",
    "    labels_array[i] = label\n",
    "images_array = images_array.numpy()\n",
    "labels_array = labels_array.numpy()\n",
    "labels_array = labels_array.astype(int)\n",
    "print(images_array.shape)\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# Your code to display one input image here (with its label)\n",
    "\n",
    "answer(\n",
    "    question=\"1.2\",\n",
    "    subquestion=\"What number is shown in the first (index 0) image?\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=Number,\n",
    ")\n",
    "\n",
    "l1_filter = np.zeros((1,1,1,1)) # update\n",
    "\n",
    "# Read the conv1 weights and apply detach().numpy() to \n",
    "\n",
    "num_input_channels = l1_filter.shape[1]\n",
    "num_out_channels = l1_filter.shape[0] # filters\n",
    "plt.figure(2)\n",
    "for x in range(num_out_channels): # filters\n",
    "    for y in range(num_input_channels): # channels\n",
    "        plt.subplot(num_input_channels, num_out_channels, y*num_out_channels + x + 1)\n",
    "        # Your code for the filter here\n",
    "        \n",
    "        plt.title(\"In: %d, Out: %d\" % (y, x))\n",
    "        plt.axis('off')\n",
    "\n",
    "answer(\n",
    "    question=\"1.2\",\n",
    "    subquestion=\"What do the conv1 filters look like? Are there (or are there not) any discernable patterns?\",\n",
    "    answer= 'FILL ME',\n",
    "    required_type=str,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
